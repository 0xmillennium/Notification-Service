# tests/e2e/test_performance.py
import pytest
import asyncio
import time
import statistics
from uuid import uuid4
from concurrent.futures import ThreadPoolExecutor, as_completed
from fastapi.testclient import TestClient
from src.entrypoints.notification_app import create_app
from src.bootstrap import bootstrap
from src.config import get_config


@pytest.fixture
def performance_test_app():
    """Create test application optimized for performance testing"""
    config = get_config()
    config.DATABASE_URL = "sqlite:///:memory:"
    messagebus = bootstrap(start_orm=True)
    app = create_app(messagebus)
    return TestClient(app)


class TestPerformance:
    """Performance and load tests for the notification service"""

    def test_notification_preferences_throughput(self, performance_test_app):
        """Test throughput for setting notification preferences"""
        num_requests = 100
        start_time = time.time()

        successful_requests = 0
        for i in range(num_requests):
            userid = uuid4().hex
            preferences_data = {
                "userid": userid,
                "notification_email": f"user{i}@example.com",
                "email_enabled": True,
                "marketing_enabled": False,
                "security_enabled": True
            }

            response = performance_test_app.post(
                "/api/v1/notification-preferences",
                json=preferences_data
            )

            if response.status_code in [200, 201]:
                successful_requests += 1

        end_time = time.time()
        duration = end_time - start_time
        throughput = successful_requests / duration

        print(f"Preferences throughput: {throughput:.2f} requests/second")
        print(f"Success rate: {successful_requests/num_requests*100:.1f}%")

        # Assert minimum performance requirements
        assert throughput > 50  # At least 50 requests per second
        assert successful_requests / num_requests > 0.95  # 95% success rate

    def test_notification_sending_throughput(self, performance_test_app):
        """Test throughput for sending notifications"""
        num_users = 50
        notifications_per_user = 2

        # First, set up users with preferences
        userids = []
        for i in range(num_users):
            userid = uuid4().hex
            userids.append(userid)

            preferences_data = {
                "userid": userid,
                "notification_email": f"user{i}@example.com",
                "email_enabled": True,
                "security_enabled": True
            }
            performance_test_app.post(
                "/api/v1/notification-preferences",
                json=preferences_data
            )

        # Now test notification sending throughput
        start_time = time.time()
        successful_notifications = 0

        for userid in userids:
            for j in range(notifications_per_user):
                notification_data = {
                    "notification_id": uuid4().hex,
                    "userid": userid,
                    "notification_type": "security_alert",
                    "subject": f"Security Alert {j}",
                    "content": "Your account was accessed from a new device"
                }

                response = performance_test_app.post(
                    "/api/v1/notifications",
                    json=notification_data
                )

                if response.status_code == 202:
                    successful_notifications += 1

        end_time = time.time()
        duration = end_time - start_time
        throughput = successful_notifications / duration

        total_expected = num_users * notifications_per_user

        print(f"Notification throughput: {throughput:.2f} notifications/second")
        print(f"Success rate: {successful_notifications/total_expected*100:.1f}%")

        # Assert minimum performance requirements
        assert throughput > 30  # At least 30 notifications per second
        assert successful_notifications / total_expected > 0.95

    def test_concurrent_preference_updates(self, performance_test_app):
        """Test concurrent updates to preferences"""
        userid = uuid4().hex
        num_concurrent_requests = 20

        def update_preferences(suffix):
            preferences_data = {
                "userid": userid,
                "notification_email": f"user{suffix}@example.com",
                "email_enabled": True,
                "marketing_enabled": suffix % 2 == 0  # Alternate values
            }

            start_time = time.time()
            response = performance_test_app.post(
                "/api/v1/notification-preferences",
                json=preferences_data
            )
            end_time = time.time()

            return {
                'status_code': response.status_code,
                'duration': end_time - start_time
            }

        # Execute concurrent requests
        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(update_preferences, i)
                for i in range(num_concurrent_requests)
            ]

            results = [future.result() for future in as_completed(futures)]

        # Analyze results
        successful_requests = [r for r in results if r['status_code'] in [200, 201]]
        durations = [r['duration'] for r in successful_requests]

        success_rate = len(successful_requests) / num_concurrent_requests
        avg_duration = statistics.mean(durations) if durations else 0
        max_duration = max(durations) if durations else 0

        print(f"Concurrent updates success rate: {success_rate*100:.1f}%")
        print(f"Average response time: {avg_duration*1000:.2f}ms")
        print(f"Max response time: {max_duration*1000:.2f}ms")

        # Assert performance requirements
        assert success_rate > 0.9  # 90% success rate for concurrent updates
        assert avg_duration < 1.0  # Average response time under 1 second
        assert max_duration < 5.0  # Max response time under 5 seconds

    def test_memory_usage_stability(self, performance_test_app):
        """Test memory usage remains stable under load"""
        import psutil
        import os

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # Perform many operations
        for batch in range(5):
            for i in range(50):
                userid = uuid4().hex

                # Set preferences
                preferences_data = {
                    "userid": userid,
                    "notification_email": f"user{i}@example.com",
                    "email_enabled": True
                }
                performance_test_app.post(
                    "/api/v1/notification-preferences",
                    json=preferences_data
                )

                # Send notification
                notification_data = {
                    "notification_id": uuid4().hex,
                    "userid": userid,
                    "notification_type": "email_verification",
                    "subject": "Test",
                    "content": "Test content"
                }
                performance_test_app.post("/api/v1/notifications", json=notification_data)

            # Check memory after each batch
            current_memory = process.memory_info().rss / 1024 / 1024
            memory_increase = current_memory - initial_memory

            print(f"Batch {batch + 1}: Memory usage: {current_memory:.2f}MB "
                  f"(+{memory_increase:.2f}MB)")

        final_memory = process.memory_info().rss / 1024 / 1024
        total_increase = final_memory - initial_memory

        print(f"Total memory increase: {total_increase:.2f}MB")

        # Assert memory doesn't grow excessively (allow for some growth)
        assert total_increase < 100  # Less than 100MB increase


class TestScalability:
    """Tests for service scalability characteristics"""

    def test_response_time_under_load(self, performance_test_app):
        """Test response times remain acceptable under increasing load"""
        load_levels = [10, 25, 50, 75, 100]
        response_times = {}

        for load_level in load_levels:
            times = []

            for i in range(load_level):
                userid = uuid4().hex
                preferences_data = {
                    "userid": userid,
                    "notification_email": f"user{i}@example.com",
                    "email_enabled": True
                }

                start_time = time.time()
                response = performance_test_app.post(
                    "/api/v1/notification-preferences",
                    json=preferences_data
                )
                end_time = time.time()

                if response.status_code in [200, 201]:
                    times.append(end_time - start_time)

            if times:
                avg_time = statistics.mean(times)
                p95_time = sorted(times)[int(len(times) * 0.95)] if len(times) > 1 else times[0]
                response_times[load_level] = {
                    'avg': avg_time,
                    'p95': p95_time
                }

                print(f"Load {load_level}: Avg={avg_time*1000:.2f}ms, "
                      f"P95={p95_time*1000:.2f}ms")

        # Verify response times don't degrade too much with load
        if len(response_times) > 1:
            low_load_avg = response_times[load_levels[0]]['avg']
            high_load_avg = response_times[load_levels[-1]]['avg']
            degradation_factor = high_load_avg / low_load_avg

            print(f"Performance degradation factor: {degradation_factor:.2f}x")

            # Assert response time doesn't degrade more than 3x
            assert degradation_factor < 3.0

    def test_error_rate_under_stress(self, performance_test_app):
        """Test error rates under stress conditions"""
        num_requests = 200
        concurrent_workers = 20

        def make_request(i):
            userid = uuid4().hex
            preferences_data = {
                "userid": userid,
                "notification_email": f"user{i}@example.com",
                "email_enabled": True
            }

            try:
                response = performance_test_app.post(
                    "/api/v1/notification-preferences",
                    json=preferences_data,
                    timeout=10
                )
                return response.status_code
            except Exception as e:
                return 500  # Treat exceptions as server errors

        # Execute stress test
        with ThreadPoolExecutor(max_workers=concurrent_workers) as executor:
            futures = [
                executor.submit(make_request, i)
                for i in range(num_requests)
            ]

            results = [future.result() for future in as_completed(futures)]

        # Analyze error rates
        success_count = len([r for r in results if r in [200, 201]])
        client_error_count = len([r for r in results if 400 <= r < 500])
        server_error_count = len([r for r in results if r >= 500])

        success_rate = success_count / num_requests
        client_error_rate = client_error_count / num_requests
        server_error_rate = server_error_count / num_requests

        print(f"Success rate: {success_rate*100:.1f}%")
        print(f"Client error rate: {client_error_rate*100:.1f}%")
        print(f"Server error rate: {server_error_rate*100:.1f}%")

        # Assert acceptable error rates under stress
        assert success_rate > 0.85  # At least 85% success rate
        assert server_error_rate < 0.05  # Less than 5% server errors


class TestResourceUsage:
    """Tests for resource usage patterns"""

    def test_database_connection_efficiency(self, performance_test_app):
        """Test efficient use of database connections"""
        # This test would monitor database connection usage
        # Implementation depends on database monitoring capabilities

        num_operations = 100

        for i in range(num_operations):
            userid = uuid4().hex

            # Operation that requires database access
            preferences_data = {
                "userid": userid,
                "notification_email": f"user{i}@example.com",
                "email_enabled": True
            }

            response = performance_test_app.post(
                "/api/v1/notification-preferences",
                json=preferences_data
            )

            assert response.status_code in [200, 201]

        # If we get here without database connection errors,
        # connection pooling is working properly
        assert True

    def test_api_rate_limiting_behavior(self, performance_test_app):
        """Test API behavior under rate limiting scenarios"""
        # Test rapid requests from single client
        userid = uuid4().hex
        rapid_requests = 50

        responses = []
        start_time = time.time()

        for i in range(rapid_requests):
            preferences_data = {
                "userid": userid,
                "notification_email": f"user{i}@example.com",
                "email_enabled": True
            }

            response = performance_test_app.post(
                "/api/v1/notification-preferences",
                json=preferences_data
            )
            responses.append(response.status_code)

            # Small delay to avoid overwhelming the test
            time.sleep(0.01)

        end_time = time.time()
        duration = end_time - start_time

        # Analyze response patterns
        success_responses = [r for r in responses if r in [200, 201]]
        rate_limit_responses = [r for r in responses if r == 429]

        print(f"Rapid requests completed in {duration:.2f}s")
        print(f"Successful: {len(success_responses)}, Rate limited: {len(rate_limit_responses)}")

        # Service should handle rapid requests gracefully
        # (either by processing them or rate limiting appropriately)
        total_handled = len(success_responses) + len(rate_limit_responses)
        assert total_handled / rapid_requests > 0.9  # 90% of requests handled
